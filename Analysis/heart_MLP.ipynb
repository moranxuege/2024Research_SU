{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install d2lzh\n",
    "\n",
    "%matplotlib inline\n",
    "import d2lzh as d2l \n",
    "from mxnet import autograd, gluon, init, nd \n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Load X_2020\n",
    "with open('X_2020.pkl', 'rb') as file:\n",
    "    X_2020 = pickle.load(file)\n",
    "    print(\"success\")\n",
    "\n",
    "# Load y_2020\n",
    "with open('y_2020.pkl', 'rb') as file:\n",
    "    y_2020 = pickle.load(file)\n",
    "    print(\"success\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(584844, 50)\n",
      "(584844,)\n"
     ]
    }
   ],
   "source": [
    "print(X_2020.shape)\n",
    "print(y_2020.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Positional arguments must have NDArray type, but got Empty DataFrame\nColumns: [BMI, PhysicalHealth, MentalHealth, SleepTime, Smoking_No, Smoking_Yes, AlcoholDrinking_No, AlcoholDrinking_Yes, Stroke_No, Stroke_Yes, DiffWalking_No, DiffWalking_Yes, Sex_Female, Sex_Male, AgeCategory_18-24, AgeCategory_25-29, AgeCategory_30-34, AgeCategory_35-39, AgeCategory_40-44, AgeCategory_45-49, AgeCategory_50-54, AgeCategory_55-59, AgeCategory_60-64, AgeCategory_65-69, AgeCategory_70-74, AgeCategory_75-79, AgeCategory_80 or older, Race_American Indian/Alaskan Native, Race_Asian, Race_Black, Race_Hispanic, Race_Other, Race_White, Diabetic_No, Diabetic_No, borderline diabetes, Diabetic_Yes, Diabetic_Yes (during pregnancy), PhysicalActivity_No, PhysicalActivity_Yes, GenHealth_Excellent, GenHealth_Fair, GenHealth_Good, GenHealth_Poor, GenHealth_Very good, Asthma_No, Asthma_Yes, KidneyDisease_No, KidneyDisease_Yes, SkinCancer_No, SkinCancer_Yes]\nIndex: []\n\n[0 rows x 50 columns]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/2631066476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_2020\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2020\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# 打印最终结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/2631066476.py\u001b[0m in \u001b[0;36mk_fold_cross_validation\u001b[0;34m(k, X, y, num_epochs, learning_rate, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# 准备数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_k_fold_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrayDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/2631066476.py\u001b[0m in \u001b[0;36mget_k_fold_data\u001b[0;34m(k, i, X, y)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_k_fold_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mfold_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfold_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(*data, **kwargs)\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Positional arguments must have NDArray type, but got Empty DataFrame\nColumns: [BMI, PhysicalHealth, MentalHealth, SleepTime, Smoking_No, Smoking_Yes, AlcoholDrinking_No, AlcoholDrinking_Yes, Stroke_No, Stroke_Yes, DiffWalking_No, DiffWalking_Yes, Sex_Female, Sex_Male, AgeCategory_18-24, AgeCategory_25-29, AgeCategory_30-34, AgeCategory_35-39, AgeCategory_40-44, AgeCategory_45-49, AgeCategory_50-54, AgeCategory_55-59, AgeCategory_60-64, AgeCategory_65-69, AgeCategory_70-74, AgeCategory_75-79, AgeCategory_80 or older, Race_American Indian/Alaskan Native, Race_Asian, Race_Black, Race_Hispanic, Race_Other, Race_White, Diabetic_No, Diabetic_No, borderline diabetes, Diabetic_Yes, Diabetic_Yes (during pregnancy), PhysicalActivity_No, PhysicalActivity_Yes, GenHealth_Excellent, GenHealth_Fair, GenHealth_Good, GenHealth_Poor, GenHealth_Very good, Asthma_No, Asthma_Yes, KidneyDisease_No, KidneyDisease_Yes, SkinCancer_No, SkinCancer_Yes]\nIndex: []\n\n[0 rows x 50 columns]"
     ]
    }
   ],
   "source": [
    "# 导入所需库\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import nn, Trainer\n",
    "from mxnet.gluon.data import ArrayDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 定义多层感知机模型\n",
    "class MLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense1 = nn.Dense(64, activation='relu')\n",
    "            self.dense2 = nn.Dense(32, activation='relu')\n",
    "            self.dense3 = nn.Dense(1, activation='sigmoid')  # 输出层使用sigmoid激活函数，输出概率值\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "# 定义RMSE作为损失函数\n",
    "def rmse_loss(output, label):\n",
    "    return nd.sqrt(nd.mean((output - label)**2))\n",
    "\n",
    "# 定义交叉验证函数\n",
    "def k_fold_cross_validation(k, X, y, num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    assert k > 1\n",
    "    fold_size = len(X) // k\n",
    "    train_losses, val_losses = [], []\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # 准备数据\n",
    "        X_train, y_train, X_valid, y_valid = get_k_fold_data(k, i, X, y)\n",
    "        train_dataset = ArrayDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "\n",
    "        val_dataset = ArrayDataset(X_valid, y_valid)\n",
    "        val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "\n",
    "        # 初始化模型\n",
    "        net = MLP()\n",
    "        net.initialize(init.Xavier(), ctx=mx.cpu())\n",
    "\n",
    "        # 定义损失函数和优化器\n",
    "        criterion = rmse_loss\n",
    "        trainer = Trainer(net.collect_params(), 'adam', {'learning_rate': learning_rate, 'wd': weight_decay})\n",
    "\n",
    "        # 训练模型\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = 0.\n",
    "            for data, label in train_loader:\n",
    "                with autograd.record():\n",
    "                    output = net(data)\n",
    "                    loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                trainer.step(batch_size)\n",
    "                train_loss += loss.mean().asscalar()\n",
    "            train_loss /= len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            # 在验证集上计算损失\n",
    "            val_loss = 0.\n",
    "            for data, label in val_loader:\n",
    "                output = net(data)\n",
    "                loss = criterion(output, label)\n",
    "                val_loss += loss.mean().asscalar()\n",
    "            val_loss /= len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # 计算验证集准确率\n",
    "            accuracy = calculate_accuracy(net, X_valid, y_valid)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "            print(f\"Fold [{i+1}/{k}], Epoch [{epoch+1}/{num_epochs}], Train RMSE: {train_loss:.4f}, Val RMSE: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, accuracies\n",
    "\n",
    "# 计算准确率\n",
    "def calculate_accuracy(net, features, labels):\n",
    "    preds = net(features)\n",
    "    preds = preds > 0.5\n",
    "    accuracy = (preds == labels.reshape(preds.shape)).mean().asscalar()\n",
    "    return accuracy\n",
    "\n",
    "# 获取K折交叉验证数据\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    fold_size = len(X) // k\n",
    "    X_train = nd.concat(X[0:i * fold_size], X[(i + 1) * fold_size:], dim=0)\n",
    "    y_train = nd.concat(y[0:i * fold_size], y[(i + 1) * fold_size:], dim=0)\n",
    "    return X_train, y_train, X[i * fold_size: (i + 1) * fold_size], y[i * fold_size: (i + 1) * fold_size]\n",
    "\n",
    "\n",
    "# 调用交叉验证函数进行训练\n",
    "k = 5\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "train_losses, val_losses, accuracies = k_fold_cross_validation(k, X_2020, y_2020, num_epochs, learning_rate, weight_decay, batch_size)\n",
    "\n",
    "# 打印最终结果\n",
    "print(f\"Average Train RMSE: {np.mean(train_losses):.4f}, Average Val RMSE: {np.mean(val_losses):.4f}, Average Val Accuracy: {np.mean(accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设 train_losses 和 val_losses 已经在你的代码中记录好了\n",
    "# 训练过程中的 epoch 数量\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "# 创建绘图\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 绘制训练集 RMSE 曲线（使用蓝色实线）\n",
    "plt.plot(epochs, train_losses, 'b-o', label='Train RMSE')\n",
    "\n",
    "# 绘制验证集 RMSE 曲线（使用橙色实线）\n",
    "plt.plot(epochs, val_losses, 'r-o', label='Val RMSE')\n",
    "\n",
    "# 设置图表标题和标签\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training and Validation RMSE')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "\n",
    "# 添加网格线\n",
    "plt.grid(True)\n",
    "\n",
    "# 自动调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = gloss.L2Loss()\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential()\n",
    "    \n",
    "    # 第一层\n",
    "    net.add(nn.Dense(14, activation='relu'))  \n",
    "    # 第二层 \n",
    "    net.add(nn.Dense(4, activation='relu'))  \n",
    "    # 输出层\n",
    "    net.add(nn.Dense(1))  # 输出层, 1个神经元\n",
    "    net.initialize()\n",
    "    return net\n",
    "\n",
    "import mxnet.ndarray as nd\n",
    "\n",
    "def binary_cross_entropy(preds, labels):\n",
    "    # 将预测值进行限制，避免出现 log(0)\n",
    "    preds = nd.clip(preds, 1e-10, 1 - 1e-10)\n",
    "    return -nd.mean(labels * nd.log(preds) + (1 - labels) * nd.log(1 - preds))\n",
    "\n",
    "def log_bce(net, features, labels):\n",
    "   \n",
    "    preds = net(features)  \n",
    "    \n",
    "    # 计算损失\n",
    "    bce_loss = binary_cross_entropy(preds, labels)\n",
    "    return bce_loss.asscalar()  \n",
    "\n",
    "def calculate_accuracy(net, features, labels):\n",
    "    # 将预测值二值化，使用0.5作为阈值\n",
    "    preds = net(features)\n",
    "    predicted_labels = (preds > 0.5).astype(labels.dtype)\n",
    "    # 计算准确率\n",
    "    return nd.mean(predicted_labels == labels).asscalar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls, accura_ls= [], [], []\n",
    "    train_iter = gdata.DataLoader(gdata.ArrayDataset(\n",
    "        train_features, train_labels), batch_size, shuffle=True)\n",
    "    # print(\"train_iter\",train_iter)\n",
    "    # 这里使用了Adam优化算法\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam', {\n",
    "        'learning_rate': learning_rate, 'wd': weight_decay})\n",
    "    # print(\"trainer:\",trainer)\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                l = loss(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "        train_ls.append(log_bce(net, train_features, train_labels))\n",
    "        accura_ls.append(calculate_accuracy(net, train_features, train_labels))\n",
    "        # print(\"train_ls in loop:\",train_ls)\n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_bce(net, test_features, test_labels))\n",
    "        # print(\"train_ls1:\",train_ls)\n",
    "    return train_ls, test_ls,accura_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet.ndarray as nd\n",
    "import numpy as np\n",
    "\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    X = nd.array(X)\n",
    "    y = nd.array(y)\n",
    "\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx], y[idx]\n",
    "        \n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            print(\"X_train type\",type(X_train))\n",
    "            print(\"X_part type\",type(X_part))\n",
    "            X_train = nd.concat([X_train, X_part], dim=0)\n",
    "            y_train = nd.concat([y_train, y_part], dim=0)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet.ndarray as nd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    X = nd.array(X.values)  # 将DataFrame转换为ndarray\n",
    "    y = nd.array(y.values)  # 将DataFrame转换为ndarray\n",
    "\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx], y[idx]\n",
    "        \n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = nd.concat([X_train, X_part], dim=0)\n",
    "            y_train = nd.concat([y_train, y_part], dim=0)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Positional arguments must have NDArray type, but got [\n[[-0.7686169  -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [-1.1493541  -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [-0.5058768  -0.4240698  -0.49003857 ...  0.          0.\n   1.        ]\n ...\n [ 0.47113892 -0.4240698   3.2810688  ...  0.          1.\n   0.        ]\n [ 1.3081315  -0.4240698  -0.49003857 ...  0.          0.\n   1.        ]\n [-0.00714252  0.3305677  -0.49003857 ...  0.          1.\n   0.        ]]\n<NDArray 116968x50 @cpu(0)>, \n[[-0.40203938 -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [-0.03074194 -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [ 0.7716381  -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n ...\n [ 1.1382157  -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [ 0.12501419 -0.4240698   0.5155901  ...  0.          1.\n   0.        ]\n [ 1.1193361   2.0913885   1.3955151  ...  0.          1.\n   0.        ]]\n<NDArray 116968x50 @cpu(0)>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/950433594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_l, valid_l, accuracy_l = k_fold(k, X_2020, y_2020, num_epochs, lr,\n\u001b[0m\u001b[1;32m      3\u001b[0m                           weight_decay, batch_size)\n\u001b[1;32m      4\u001b[0m print('%d-fold validation: avg train loss %f, avg valid loss %f, accuracy %f'\n\u001b[1;32m      5\u001b[0m       % (k, train_l, valid_l, accuracy_l))\n",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/4049394175.py\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_l_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_l_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccura_l_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_k_fold_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         train_ls, valid_ls,accura_ls = train(net, *data, num_epochs, learning_rate,\n",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/2209609543.py\u001b[0m in \u001b[0;36mget_k_fold_data\u001b[0;34m(k, i, X, y)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_part\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_part\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_part\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(*data, **kwargs)\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Positional arguments must have NDArray type, but got [\n[[-0.7686169  -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [-1.1493541  -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [-0.5058768  -0.4240698  -0.49003857 ...  0.          0.\n   1.        ]\n ...\n [ 0.47113892 -0.4240698   3.2810688  ...  0.          1.\n   0.        ]\n [ 1.3081315  -0.4240698  -0.49003857 ...  0.          0.\n   1.        ]\n [-0.00714252  0.3305677  -0.49003857 ...  0.          1.\n   0.        ]]\n<NDArray 116968x50 @cpu(0)>, \n[[-0.40203938 -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [-0.03074194 -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [ 0.7716381  -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n ...\n [ 1.1382157  -0.4240698  -0.49003857 ...  0.          1.\n   0.        ]\n [ 0.12501419 -0.4240698   0.5155901  ...  0.          1.\n   0.        ]\n [ 1.1193361   2.0913885   1.3955151  ...  0.          1.\n   0.        ]]\n<NDArray 116968x50 @cpu(0)>]"
     ]
    }
   ],
   "source": [
    "\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 220, 0.00005, 0, 32\n",
    "train_l, valid_l, accuracy_l = k_fold(k, X_2020, y_2020, num_epochs, lr,\n",
    "                          weight_decay, batch_size)\n",
    "print('%d-fold validation: avg train loss %f, avg valid loss %f, accuracy %f'\n",
    "      % (k, train_l, valid_l, accuracy_l))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP finding\n",
    "感觉准确性不是很高，也有可能是因为网络设计或者手动调参数的问题，这个太容易梯度消失了，lr大了容易梯度消失，小了容易loss变大，试一下Random forest + GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "Traceback (most recent call last):\n  File \"../src/c_api/c_api_ndarray.cc\", line 59\nMXNetError: Check failed: inp->shape().Size() < (int64_t{1} << 31) - 1 (218904208384 vs. 2147483647) : [SetNDInputsOutputs] Size of tensor you are trying to allocate is larger than 2^31 elements. Please build with flag USE_INT64_TENSOR_SIZE=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/602552701.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mX_2020\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0my_2020\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m train_l, valid_l, accuracy_l = k_fold(k, X_2020, y_2020, num_epochs, lr, \n\u001b[0m\u001b[1;32m     74\u001b[0m                                       weight_decay, batch_size)\n\u001b[1;32m     75\u001b[0m print('%d-fold validation: avg train loss %f, avg valid loss %f, accuracy %f'\n",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/602552701.py\u001b[0m in \u001b[0;36mk_fold\u001b[0;34m(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_k_fold_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtrain_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccura_ls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtrain_l_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_ls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/602552701.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_features, train_labels, test_features, test_labels, num_epochs, learning_rate, weight_decay, batch_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtrain_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0maccura_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pk/cx38wkw96h94vrlsy8lp1bqh0000gp/T/ipykernel_12757/3481627185.py\u001b[0m in \u001b[0;36mcalculate_accuracy\u001b[0;34m(net, features, labels)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_k_fold_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(data, axis, keepdims, exclude, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out, is_np_op, output_is_list)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mout_stypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     check_call(_LIB.MXImperativeInvokeEx(\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: Traceback (most recent call last):\n  File \"../src/c_api/c_api_ndarray.cc\", line 59\nMXNetError: Check failed: inp->shape().Size() < (int64_t{1} << 31) - 1 (218904208384 vs. 2147483647) : [SetNDInputsOutputs] Size of tensor you are trying to allocate is larger than 2^31 elements. Please build with flag USE_INT64_TENSOR_SIZE=1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd, gluon\n",
    "\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    \n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part = nd.array(X.iloc[idx].values)  # Convert DataFrame to NDArray\n",
    "        y_part = nd.array(y.iloc[idx].values)  # Convert DataFrame to NDArray\n",
    "        \n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = nd.concat(X_train, X_part, dim=0)  # Concatenate NDArray\n",
    "            y_train = nd.concat(y_train, y_part, dim=0)  # Concatenate NDArray\n",
    "            \n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_ls, test_ls, accura_ls = [], [], []\n",
    "    train_iter = gluon.data.DataLoader(gluon.data.ArrayDataset(train_features, train_labels), \n",
    "                                       batch_size, shuffle=True)\n",
    "    \n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam', \n",
    "                            {'learning_rate': learning_rate, 'wd': weight_decay})\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            with autograd.record():\n",
    "                l = gloss.L2Loss()(net(X), y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "    \n",
    "        train_ls.append(log_rmse(net, train_features, train_labels))\n",
    "        accura_ls.append(calculate_accuracy(net, train_features, train_labels))\n",
    "        \n",
    "        if test_labels is not None:\n",
    "            test_ls.append(log_rmse(net, test_features, test_labels)) # type: ignore\n",
    "    \n",
    "    return train_ls, test_ls, accura_ls\n",
    "\n",
    "def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay, batch_size):\n",
    "    train_l_sum, valid_l_sum, accura_l_sum = 0, 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = get_net()\n",
    "        train_ls, valid_ls, accura_ls = train(net, *data, num_epochs, learning_rate, weight_decay, batch_size)\n",
    "        \n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        accura_l_sum += accura_ls[-1]\n",
    "        \n",
    "        if i == 0:\n",
    "            d2l.semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'rmse',\n",
    "                         range(1, num_epochs + 1), valid_ls,\n",
    "                         ['train', 'valid'])\n",
    "        \n",
    "        print('fold %d, train loss %f, valid loss %f, accuracy %f'\n",
    "              % (i, train_ls[-1], valid_ls[-1], accura_ls[-1]))\n",
    "    \n",
    "    return train_l_sum / k, valid_l_sum / k, accura_l_sum / k\n",
    "\n",
    "# 之后调用 k_fold 函数\n",
    "k, num_epochs, lr, weight_decay, batch_size = 5, 220, 0.05, 0, 160\n",
    "X_2020 = X_2020.astype(np.float32)\n",
    "y_2020 = y_2020.astype(np.float32)\n",
    "train_l, valid_l, accuracy_l = k_fold(k, X_2020, y_2020, num_epochs, lr, \n",
    "                                      weight_decay, batch_size)\n",
    "print('%d-fold validation: avg train loss %f, avg valid loss %f, accuracy %f'\n",
    "      % (k, train_l, valid_l, accuracy_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
